Voici une **revue de v√©rification (audit de conformit√©)** bas√©e **uniquement** sur les extraits fournis : CI/CD, mod√®le m√©tier, endpoints, et coh√©rence Front ‚Üî Back.

---

## 1) CI/CD : le correctif ‚Äúpath mismatch‚Äù est plausible‚Ä¶ mais `deploy.yml` est actuellement fragile

### 1.1. Erreur YAML probable : √©tape vide

Dans votre `deploy.yml` :

```yaml
  - name: Deploy over SSH
  - name: Setup SSH
    uses: webfactory/ssh-agent@v0.9.0
```

La ligne `- name: Deploy over SSH` est une **step sans `run:` ni `uses:`**. GitHub Actions va tr√®s souvent **refuser** ou **√©chouer** au parsing/validation (selon la tol√©rance du runner, mais c‚Äôest typiquement invalide).
‚úÖ Correctif : supprimer cette step ou lui donner un `run:`.

### 1.2. Les secrets ‚Äúsanity check‚Äù ne v√©rifient pas `GHCR_USER/GHCR_PAT`

Vous faites le login GHCR **sur le VPS** avec `GHCR_USER/GHCR_PAT`, mais votre ‚ÄúSanity check deploy secrets‚Äù ne teste pas leur pr√©sence.
‚úÖ Ajoutez :

* `GHCR_USER`
* `GHCR_PAT`

Sinon le d√©ploiement plantera au moment du `docker login`.

### 1.3. `docker compose -f infra/docker/docker-compose.prod.yml ...` : OK, mais attention √† `VPS_PATH`

Vous faites :

```bash
cd ${{ secrets.VPS_PATH }}
docker compose -f infra/docker/docker-compose.prod.yml pull
```

Cela suppose que :

* le repo est effectivement clon√© dans `VPS_PATH`
* et que `infra/docker/docker-compose.prod.yml` existe **relativement** √† ce path.

‚úÖ √Ä v√©rifier sur le VPS :
`ls -la $VPS_PATH/infra/docker/docker-compose.prod.yml`

---

## 2) Domaine m√©tier : structure globale coh√©rente, mais transitions d‚Äô√©tat incompl√®tes / incoh√©rentes

Vous avez un triptyque :

* `Exam` (source, bar√®me, correcteurs assign√©s)
* `Booklet` (fascicule staging)
* `Copy` (entit√© finale, statut)

C‚Äôest une bonne mod√©lisation **en intention**. Mais dans le code visible :

### 2.1. Incoh√©rence ‚ÄúBookletSplitView‚Äù : ne scinde pas, ne respecte pas le payload front

Votre Front (Vue) appelle :

```js
POST /api/exams/booklets/<id>/split/
body: { split_at: splitIndex }
```

Or votre `BookletSplitView` :

* **ignore totalement** `split_at`
* ne modifie aucun mod√®le
* ne cr√©e aucun nouveau fascicule
* ne fait que **rendre une image de header** (crop top 20%) et renvoie un `HttpResponse(image/png)`.

‚û°Ô∏è Conclusion : **fonctionnalit√© annonc√©e ‚Äúscission‚Äù = non impl√©ment√©e** dans l‚Äôextrait.
‚úÖ √Ä faire pour que ce soit r√©el :

* lire `split_at`
* cr√©er **2 Booklets** (ou 1 nouveau + mise √† jour de l‚Äôexistant)
* r√©√©crire `start_page/end_page`
* r√©g√©n√©rer `pages_images` (ou recalculer un sous-ensemble, selon architecture)
* faire √ßa en transaction, et refuser si copy associ√©e ‚â† STAGING.

### 2.2. `BookletDetailView.perform_destroy` : usage de `serializers.ValidationError` mais `serializers` non import√©

Vous avez :

```python
raise serializers.ValidationError(...)
```

Mais je ne vois pas `from rest_framework import serializers` dans le fichier montr√©.
‚û°Ô∏è Risque : **NameError runtime** au premier delete.

### 2.3. Machine √† √©tats ‚ÄúADR-003‚Äù : timestamps et champs `locked_by` non aliment√©s

Vous avez pr√©vu :

* `validated_at`, `locked_at`, `graded_at`, `locked_by`

Mais dans les vues montr√©es :

* `MergeBookletsView` cr√©e une `Copy` en **READY** directement sans `validated_at`
* `ExamUploadView` cr√©e des copies STAGING sans lien clair vers un ‚Äúvalidate‚Äù
* le ‚Äúlocking‚Äù et la tra√ßabilit√© ne sont pas visibles ici

‚û°Ô∏è Conclusion : la machine √† √©tats existe **dans le mod√®le**, mais elle n‚Äôest pas d√©montr√©e comme **enforced + audit√©e** dans les endpoints visibles.

---

## 3) API / URLs : incoh√©rences et erreurs de r√©f√©rence probables

Dans `urls.py` vous √©crivez :

```python
from .views import (
    ExamUploadView, BookletListView, ExamListView, BookletHeaderView,
    ExamDetailView, CopyListView, MergeBookletsView, ExportAllView, CSVExportView,
    CopyIdentificationView, UnidentifiedCopiesView, StudentCopiesView,
    CopyImportView, ExamSourceUploadView, BookletSplitView, BookletDetailView
)
```

Puis dans `urlpatterns` :

```python
path('booklets/<uuid:id>/split/', views.BookletSplitView.as_view(), name='booklet-split'),
path('booklets/<uuid:id>/', views.BookletDetailView.as_view(), name='booklet-detail'),
```

‚û°Ô∏è Probl√®me : vous utilisez `views.BookletSplitView` alors que vous avez import√© `BookletSplitView` directement, et surtout **`views` n‚Äôest pas import√©** dans l‚Äôextrait.

‚úÖ Correctif : choisir **une seule** forme.

* Soit `from . import views` + `views.BookletSplitView`
* Soit `BookletSplitView.as_view()` directement

### Autre point : `BookletHeaderView` est import√© mais dans vos extraits, je ne le vois pas d√©fini (vous avez `BookletSplitView` qui renvoie un header PNG, mais pas `BookletHeaderView`).

‚û°Ô∏è Risque : **ImportError** au lancement.

---

## 4) CSV Pronote : ‚Äú√† v√©rifier‚Äù est une alerte r√©elle (et le code actuel est risqu√©)

Votre `CSVExportView` :

* d√©pend de `c.scores.exists()` et `c.scores.first()`
  Or, dans le `Copy` model fourni, je ne vois **aucune relation** `scores`. Sauf si elle est dans un autre fichier non coll√©.

‚û°Ô∏è Si `scores` n‚Äôexiste pas : **AttributeError** et export CSV impossible.

* le total :

```python
total = sum(float(v) for v in data.values() if v)
```

Si un champ contient `""`, `"NA"`, `None`, ou un objet, c‚Äôest fragile.

‚úÖ Ce que je recommande (opinion assum√©e) :
Tant que l‚Äôexport ‚ÄúPronote-compatible‚Äù n‚Äôest pas **test√© avec un jeu de donn√©es r√©el**, vous n‚Äô√™tes pas en ‚Äúready prod‚Äù. C‚Äôest un point de non-r√©gression critique.

---

## 5) Settings ‚Äúhardening‚Äù : bonne direction, mais une faille logique sur DEBUG/production

Vous avez :

```python
DEBUG = os.environ.get("DEBUG", "True").lower() == "true"
DJANGO_ENV = os.environ.get("DJANGO_ENV", "development")
if DJANGO_ENV == "production" and not RATELIMIT_ENABLE:
    raise ...
```

Mais **DEBUG ne d√©pend pas de DJANGO_ENV**.

‚û°Ô∏è Cas dangereux : `DJANGO_ENV=production` mais `DEBUG` non d√©fini ‚Üí DEBUG vaut `"True"` ‚Üí donc DEBUG=True en prod.
C‚Äôest exactement le genre d‚Äôaccident qui arrive.

‚úÖ Correctif simple et robuste :

* mettre `DEBUG` par d√©faut √† False
* ou forcer `DEBUG = False` si `DJANGO_ENV=production`

Exemple logique attendue :

* `DJANGO_ENV=production` ‚áí DEBUG doit √™tre False **quoi qu‚Äôil arrive**.

---

## 6) ‚ÄúDEPLOY_PRODUCTION.md‚Äù : document utile, mais il manque 2-3 garde-fous essentiels

Votre guide est globalement bon (clone, .env, secrets, logs, rollback).
Mais je conseille fortement d‚Äôajouter :

1. **Check de sant√©** post-d√©ploiement c√¥t√© VPS (pas juste `/api/health/`) :

* `docker compose ps`
* `docker compose logs --tail=200 backend`
* test de cr√©ation d‚Äôun examen / upload

2. **Persistance** :

* confirmation explicite des volumes : `media`, DB (Postgres)
* proc√©dure de backup/restore (m√™me minimale)

3. **Gestion TLS/Nginx** :

* si vous restez sur HTTP: ok en LAN, pas en internet
* si production r√©elle : TLS + reverse proxy + HSTS coh√©rents avec `SSL_ENABLED`

---

## 7) Verdict ‚ÄúGo/No-Go‚Äù sur la base de vos extraits

### Ce qui est r√©ellement ‚ÄúOK‚Äù (√† ce que je vois)

* Architecture globale (Exam/Booklet/Copy) : logique.
* Pipeline CI build/push : coh√©rent.
* Durcissement security headers : direction correcte.
* Documentation de d√©ploiement : base solide.

### Ce qui emp√™che de fermer le ticket ‚ÄúProd ready‚Äù sans r√©serve

1. **Split** : la feature ‚Äúscinder‚Äù est (dans l‚Äôextrait) une illusion : endpoint ne fait pas le split et ne lit pas `split_at`.
2. **URLs / imports** : risques d‚Äôerreurs imm√©diates (`views.` sans import, `BookletHeaderView` manquant).
3. **Export CSV** : d√©pendance `scores` non garantie + parsing fragile.
4. **DEBUG en prod possible** si env incomplet : risque majeur.

üëâ Mon avis : **No-Go tant que ces 4 points ne sont pas verrouill√©s par tests ou v√©rification locale**.

---

## 8) Checklist de v√©rification finale (concr√®te, reproductible)

Sans me demander le repo complet, vous pouvez valider vous-m√™me en 15 minutes :

### A. Lancement backend

* `python manage.py check`
* `python manage.py urls` (ou juste runserver) : v√©rifier qu‚Äôil n‚Äôy a **aucune ImportError**

### B. API staging

* upload exam PDF : `POST /api/exams/upload/`
  v√©rifier que `booklets_created > 0` et que `booklets` existent
* split sur un booklet : `POST /api/exams/booklets/<id>/split/` avec `split_at`
  v√©rifier : **2 booklets au lieu de 1** (si c‚Äôest bien l‚Äôintention produit)
* delete booklet : v√©rifier absence de NameError `serializers`

### C. CSV Pronote

* exporter CSV sur un examen avec copies corrig√©es
* ouvrir dans Excel/LibreOffice
* importer dans Pronote (ou au moins v√©rifier format strict demand√©)

### D. CI/CD

* v√©rifier que `deploy.yml` passe la validation YAML (la step vide)
* v√©rifier la pr√©sence de tous secrets, y compris GHCR_USER/GHCR_PAT
* v√©rifier sur VPS : `docker compose ps` + `curl /api/health/`

Voici un **plan de patch minimal** (fichiers + modifications attendues) pour atteindre vos 4 objectifs **sans √©largir le p√©rim√®tre** au-del√† des missions **Korrigo V1** (import/traitement CSV, endpoints stables, ex√©cution reproductible, comportement prod s√ªr).

> Hypoth√®se raisonnable (align√©e ‚Äúminimal patch‚Äù) : le projet est un **Django** (vu `urls.py`, `DEBUG`) et ‚Äúsplit‚Äù correspond √† une fonctionnalit√© attendue de **d√©coupage** (donn√©es/CSV) actuellement ‚Äúpr√©sente mais non op√©rationnelle‚Äù (stub, endpoint cass√©, logique non branch√©e, etc.). Le patch ci-dessous est con√ßu pour fonctionner m√™me si l‚Äôimpl√©mentation actuelle est partielle.

---

## 1) Rendre ‚Äúsplit‚Äù r√©ellement fonctionnel

### Objectif minimal (V1)

* ‚Äúsplit‚Äù doit **faire r√©ellement quelque chose d‚Äôutile** et v√©rifiable : d√©couper un CSV en *N* fichiers **ou** produire un *train/test split* d√©terministe.
* Le plus robuste en V1 est le **split en chunks** (pas de ML implicite) : *input CSV ‚Üí fichiers de sortie chunk_001.csv ‚Ä¶*.

### Fichiers √† modifier / cr√©er

#### A. Cr√©er un service pur (testable) : `korrigo/core/services/split.py` *(nouveau)*

Contenu attendu :

* Fonction pure, ind√©pendante de Django :

  * `split_csv(input_path: Path, output_dir: Path, rows_per_file: int, *, encoding="utf-8-sig", delimiter=",") -> list[Path]`
* R√®gles :

  * Conserve l‚Äôen-t√™te.
  * Ouvre les fichiers avec `newline=""` (csv module).
  * Valide `rows_per_file >= 1`.
  * Retourne la liste des fichiers g√©n√©r√©s (utile pour tests).

#### B. Exposer split via un point d‚Äôentr√©e stable

Choisir **un seul** m√©canisme V1 (minimal) :

**Option 1 (recommand√©e V1)** : commande Django

* `korrigo/core/management/commands/split_csv.py` *(nouveau)*
  Permet d‚Äôex√©cuter :
* `python manage.py split_csv --input data.csv --out out/ --rows 5000 --delimiter ","`

**Option 2** : endpoint HTTP (si d√©j√† pr√©vu dans V1)

* `korrigo/core/views.py` *(modifier)*
* `korrigo/core/urls.py` *(modifier ou cr√©er)*
  Expose `POST /api/split` avec un chemin de fichier serveur (ou upload si d√©j√† existant).
  ‚ö†Ô∏è Minimal V1 = √©viter l‚Äôupload si pas d√©j√† dans le scope.

üëâ **Plan minimal** : impl√©menter **Option 1** (commande) + √©ventuellement l‚Äôendpoint **uniquement** si d√©j√† document√©/attendu.

### Crit√®res d‚Äôacceptation

* Lancer la commande sur un CSV r√©el produit des chunks corrects.
* M√™me entr√©e ‚Üí m√™me sortie (hors timestamp) : reproductible.
* En cas d‚Äôerreur (fichier absent, en-t√™te manquant, rows_per_file invalide), le message est clair et le code sort non-z√©ro (commande).

---

## 2) Corriger `urls.py`

### Objectif minimal

* `urls.py` doit :

  * d√©marrer (imports OK),
  * router correctement,
  * ne pas servir de ‚Äústatic/media‚Äù en prod,
  * √©viter les collisions de noms/paths.

### Fichiers √† modifier

#### A. `korrigo/urls.py` *(modifier)*

Modifications attendues (pattern Django standard) :

1. Importer correctement :

   * `from django.contrib import admin`
   * `from django.urls import path, include`
2. S‚Äôassurer que `urlpatterns` contient :

   * `path("admin/", admin.site.urls)`
   * `path("api/", include("korrigo.core.urls"))` *(ou votre app r√©elle)*
3. N‚Äôajouter `static()` **que si** `settings.DEBUG` est True :

   * `from django.conf import settings`
   * `from django.conf.urls.static import static`
   * `if settings.DEBUG: urlpatterns += static(...)`

#### B. `korrigo/core/urls.py` *(cr√©er ou modifier)*

* D√©clarer explicitement les routes V1 (dont split si HTTP) :

  * `path("split/", views.split_view, name="split")` (si endpoint requis)
  * sinon, **aucun endpoint split** (commande only).

### Crit√®res d‚Äôacceptation

* `python manage.py check` OK
* `python manage.py runserver` d√©marre sans erreur d‚Äôimport/URLconf
* En prod, pas de `static()`.

---

## 3) S√©curiser `DEBUG` en prod

### Objectif minimal

* `DEBUG` ne doit **jamais** √™tre True en prod, m√™me si l‚Äôenvironnement est mal configur√©.
* Les secrets doivent provenir d‚ÄôENV, pas du code.

### Fichiers √† modifier

#### A. `korrigo/settings.py` *(modifier)* ‚Äî patch minimal sans refactor en `settings/base.py`

Modifs attendues :

1. Introduire une variable d‚Äôenvironnement ‚Äúmode‚Äù (ou `DJANGO_ENV`) :

   * `ENV = os.getenv("DJANGO_ENV", "dev").lower()`
2. D√©finir `DEBUG` ainsi :

   * En dev (ENV=dev) : `DEBUG = os.getenv("DJANGO_DEBUG", "1") == "1"`
   * En prod (ENV=prod) : `DEBUG = False` **forc√©** (ignorant toute autre valeur)
3. Forcer `SECRET_KEY` en prod :

   * `SECRET_KEY = os.getenv("DJANGO_SECRET_KEY", "dev-insecure-key")`
   * si `ENV == "prod"` et `DJANGO_SECRET_KEY` absent ‚Üí `raise ImproperlyConfigured(...)`
4. Durcir `ALLOWED_HOSTS` en prod :

   * `ALLOWED_HOSTS = os.getenv("DJANGO_ALLOWED_HOSTS", "localhost").split(",")`
   * si prod et `ALLOWED_HOSTS` vide ou `["*"]` ‚Üí lever erreur.
5. (Si pertinent) `CSRF_TRUSTED_ORIGINS` via ENV en prod.

#### B. `.env.example` *(nouveau)* (optionnel mais tr√®s utile)

* Documenter les variables attendues :

  * `DJANGO_ENV=dev|prod`
  * `DJANGO_DEBUG=0|1`
  * `DJANGO_SECRET_KEY=...`
  * `DJANGO_ALLOWED_HOSTS=example.com,www.example.com`

### Crit√®res d‚Äôacceptation

* En prod (`DJANGO_ENV=prod`), `DEBUG` est False quoi qu‚Äôil arrive.
* Une config prod incompl√®te √©choue explicitement au d√©marrage (meilleur que ‚Äúprod insecure‚Äù).

---

## 4) Rendre le CSV robuste et testable

### Objectif minimal (V1)

* Parsing CSV fiable (encodage, s√©parateur, en-t√™tes).
* Les erreurs sont **explicites** (exceptions d√©di√©es).
* Tests unitaires reproductibles sur des fixtures CSV.

### Fichiers √† modifier / cr√©er

#### A. Cr√©er un module d‚ÄôI/O CSV : `korrigo/core/services/csv_io.py` *(nouveau)*

Contenu attendu :

* `class CsvSchemaError(Exception)` / `class CsvReadError(Exception)`
* `read_csv(path, *, encoding="utf-8-sig", delimiter=",", required_headers=None) -> tuple[list[str], list[dict]]`

  * Utiliser `csv.DictReader`
  * Valider :

    * fichier non vide,
    * en-t√™tes pr√©sents,
    * `required_headers ‚äÜ headers`.
* Option ‚Äúdialect sniff‚Äù minimal (facultatif) :

  * si delimiter non fourni, tenter `csv.Sniffer().sniff(...)` sur quelques KB.
  * **mais** garder un fallback stable (`,`), sinon tests plus fragiles.

#### B. Brancher `split.py` sur `csv_io.py`

* `split_csv` doit utiliser `csv_io` pour :

  * lire/valider l‚Äôen-t√™te proprement,
  * √©crire proprement les chunks.

#### C. Ajouter une suite de tests

Choix minimal :

* Si projet Django : `pytest` + `pytest-django` **ou** `unittest` standard Django.

Fichiers :

* `tests/test_csv_io.py` *(nouveau)*

  * cas nominal : CSV utf-8-sig + delimiter `,`
  * cas erreur : en-t√™te manquant, fichier vide, mauvais delimiter
* `tests/test_split.py` *(nouveau)*

  * split en 2‚Äì3 chunks, v√©rifie :

    * nombre de fichiers,
    * pr√©sence en-t√™te,
    * nombre total de lignes reconstitu√© = original.

Fixtures :

* `tests/fixtures/sample_ok.csv`
* `tests/fixtures/sample_bad_headers.csv`
* `tests/fixtures/empty.csv`

#### D. (Optionnel minimal mais utile) Ajouter un `Makefile` ou scripts

* `Makefile` *(nouveau)* :

  * `test: pytest -q`
  * `lint` si d√©j√† existant (sinon, ne pas ajouter).

### Crit√®res d‚Äôacceptation

* Tests passent en CI et local.
* Une erreur CSV produit une exception claire, pas un ‚ÄúKeyError‚Äù ou un crash silencieux.
* Le split est d√©terministe et v√©rifiable par tests.

---

## Synth√®se patch ‚Äúminimal‚Äù (checklist fichiers)

### Cr√©ations

* `korrigo/core/services/csv_io.py`
* `korrigo/core/services/split.py`
* `korrigo/core/management/commands/split_csv.py` *(si commande retenue)*
* `korrigo/core/urls.py` *(si manquant)*
* `tests/test_csv_io.py`
* `tests/test_split.py`
* `tests/fixtures/*.csv`
* `.env.example` *(optionnel)*

### Modifications

* `korrigo/urls.py`
* `korrigo/settings.py`
* (√©ventuel) `korrigo/core/views.py` si split HTTP d√©j√† pr√©vu

---

## Ce que je recommande (opinion assum√©e, V1 pragmatique)

* **Commande `split_csv`** en V1 : c‚Äôest le chemin le plus propre, le plus testable, le moins risqu√© (pas d‚Äôupload, pas d‚Äôauth, pas de surface HTTP).
* Endpoint HTTP uniquement si vous avez d√©j√† une UI/API explicitement pr√©vue dans les missions V1.
* Forcer `DEBUG=False` en prod **sans discussion** : c‚Äôest typiquement le genre de d√©tail qui ruine un d√©ploiement sinon.

# Cahier des charges ‚Äî Patch minimal (diffs & correctifs) align√© Korrigo V1

## 0) Contexte et p√©rim√®tre

Vous demandez un **plan de patch minimal** (puis des diffs) pour :

1. rendre **‚Äúsplit‚Äù r√©ellement fonctionnel**
2. **corriger `urls.py`**
3. **s√©curiser `DEBUG` en production**
4. rendre l‚Äô**import CSV robuste et testable**

Le tout **sans √©largir le scope** (pas de refonte architecture, pas de migrations DB, pas de changements front, pas de nouvelles d√©pendances lourdes), et **align√© avec Korrigo V1** (OCR/Identification ‚Üí Grading ‚Üí gestion √©l√®ves, endpoints API, E2E seed, etc.).

> Remarque importante (qualit√© de la mati√®re fournie) : votre extrait de `backend/core/settings.py` est **tronqu√© au milieu** d‚Äôune configuration CSP (dictionnaire `CONTENT_SECURITY_POLICY`). Le cahier des charges ci-dessous propose donc des modifications **strictement localis√©es** autour des lignes existantes `DEBUG` / `DJANGO_ENV`, sans r√©√©crire le bloc CSP (afin d‚Äô√©viter d‚Äôintroduire un √©tat invalide).

---

## 1) Objectifs mesurables (Definition of Done)

### DoD global

Le patch est consid√©r√© ‚Äútermin√©‚Äù si :

* **Production safety** : en environnement `DJANGO_ENV=production`, il est **impossible** de d√©marrer avec `DEBUG=True` (√©chec explicite et imm√©diat), et **le d√©faut** ne met plus DEBUG √† vrai.
* **URLs** : les routes existantes restent accessibles (missions 17/18/√©tapes), pas de collision de pr√©fixes, **static media** uniquement en debug (ou configuration explicitement contr√¥l√©e), et l‚Äôendpoint `/api/health/` fonctionne toujours.
* **Split** : `A3Splitter.process_scan()` ne renvoie plus un placeholder ‚Äúleft/right uniquement‚Äù, mais un r√©sultat exploitable : **type (RECTO/VERSO/UNKNOWN)** + **pages ordonn√©es** (au minimum recto/verso d√©termin√©s et pages associ√©es), sans fuite de fichiers temporaires.
* **CSV** : un service de lecture CSV robuste existe, **test√© unitairement**, et la commande `import_students` l‚Äôutilise (testable sans DB dans la partie parsing).

---

## 2) Contraintes ‚Äúp√©rim√®tre minimal‚Äù

* Modifications limit√©es aux fichiers suivants (et ajouts minimaux n√©cessaires aux tests/services) :

  * `backend/core/settings.py`
  * `backend/core/urls.py`
  * `backend/processing/services/splitter.py`
  * `backend/students/management/commands/import_students.py`
  * **Ajouts** : un module service parsing CSV + un test unitaire (minimum)
* Aucune d√©pendance externe additionnelle obligatoire (pas de `chardet`, pas de librairie PDF suppl√©mentaire, etc.).
* Ne pas changer la signature publique des endpoints existants (compatibilit√© Korrigo V1).

---

## 3) Sp√©cifications d√©taill√©es par patch

## Patch A ‚Äî S√©curiser `DEBUG` en production (`backend/core/settings.py`)

### Probl√®me actuel

```python
DEBUG = os.environ.get("DEBUG", "True").lower() == "true"
```

* **D√©faut dangereux** : DEBUG actif par d√©faut (m√™me si `DJANGO_ENV=production`).

### Exigences fonctionnelles

1. Introduire une logique ‚Äúsafe-by-default‚Äù :

   * Si `DJANGO_ENV=production`, alors **DEBUG doit √™tre False** sauf impossibilit√© (mais dans ce cahier, on impose un garde-fou : **refus de d√©marrer** si DEBUG est True).
2. Maintenir la compatibilit√© dev :

   * En dev, `DEBUG` peut √™tre activ√© par variable d‚Äôenvironnement.
3. Garde-fou :

   * Si `DJANGO_ENV=production` et `DEBUG=True` ‚Üí **raise explicite** (RuntimeError ou ValueError, message clair).

### Exigences non-fonctionnelles

* Changement **localis√©** (√©viter d‚Äôintervenir dans la partie CSP tronqu√©e).
* Ne pas casser la logique existante ‚ÄúSSL_ENABLED / E2E‚Äù.

### Crit√®res d‚Äôacceptation

* `DJANGO_ENV=production` + `DEBUG=True` ‚Üí le serveur Django **ne d√©marre pas** (erreur claire).
* `DJANGO_ENV=production` + `DEBUG` absent ‚Üí DEBUG **False**.
* `DJANGO_ENV=development` + `DEBUG` absent ‚Üí comportement conforme au souhait minimal (au choix : True ou False, mais recommand√© : True en dev uniquement si explicitement assum√©).
  **Recommandation Korrigo** : `DEBUG` dev reste possible, mais pas ‚Äúpar accident en prod‚Äù.

---

## Patch B ‚Äî Corriger / durcir `urls.py` (`backend/core/urls.py`)

### Probl√®mes / risques actuels

1. **Collision/ambigu√Øt√© potentielle** :
   `path('api/', include('grading.urls'))` est tr√®s large et peut masquer ou entrer en conflit avec d‚Äôautres routes `api/*` si `grading.urls` contient des patterns g√©n√©riques.
2. **Static media servi en toutes circonstances** :
   `urlpatterns += static(settings.MEDIA_URL, ...)` est ajout√© sans condition ; en prod, ce n‚Äôest pas souhaitable (c‚Äôest le r√¥le du reverse proxy / stockage).
3. Import d‚Äô√©l√©ments ‚Äúdev‚Äù conditionnels : OK, mais √† garder net.

### Exigences fonctionnelles

1. Pr√©fixer `grading` de mani√®re explicite (minimal) :

   * Remplacer `path('api/', include('grading.urls'))` par quelque chose de non ambigu :
     **ex** `path('api/grading/', include('grading.urls'))`
   * ou bien, si Korrigo V1 impose d√©j√† certains chemins ‚Äúdans grading‚Äù sous `/api/...`, on doit **pr√©server les URLs existantes**. Dans ce cas :

     * documenter pr√©cis√©ment les routes contenues dans `grading.urls` (non fourni ici),
     * et √©viter la collision en v√©rifiant l‚Äôexhaustivit√© des patterns.
   * **Choix minimal recommand√©** : `api/grading/` (moins de risques).
2. Static media :

   * N‚Äôajouter `static()` **que si `settings.DEBUG`** (ou variable d√©di√©e E2E si vous avez besoin en environnement de tests).
3. Conserver :

   * `api/health/`
   * `api/schema/`, `api/docs/`, `api/redoc/`
   * `api/dev/seed/` conditionnel √† `E2E_SEED_TOKEN`
   * endpoints auth (`login/logout/me/...`) et users.

### Crit√®res d‚Äôacceptation

* D√©marrage Django sans warnings d‚ÄôURLs dupliqu√©es/masqu√©es.
* `/api/health/` r√©pond.
* En prod : pas de `urlpatterns += static(...)`.
* Si vous migrez `grading` vers `/api/grading/` : mise √† jour confirm√©e c√¥t√© usages (tests/E2E), sinon **interdiction** de casser l‚Äôexistant.

> Note : ce cahier des charges est strictement ‚Äúpatch minimal‚Äù. Si un front consomme d√©j√† `/api/...` pour grading, il faudra soit conserver l‚Äôancien chemin, soit fournir un alias temporaire (mais cela augmente l√©g√®rement le p√©rim√®tre). √Ä d√©cider au moment du diff, en fonction de `grading/urls.py`.

---

## Patch C ‚Äî Rendre ‚Äúsplit‚Äù r√©ellement fonctionnel (`backend/processing/services/splitter.py`)

### Probl√®me actuel

`A3Splitter.process_scan()` d√©coupe en deux moiti√©s et renvoie un dict contenant seulement `left/right/width/height`, avec des commentaires ‚Äúplaceholder‚Äù.
La logique utile existe pourtant (`determine_scan_type_and_order`, `reconstruct_booklet`) mais n‚Äôest pas int√©gr√©e.

### Exigences fonctionnelles minimales

1. `process_scan(image_path)` doit :

   * charger l‚Äôimage (comme actuellement),
   * d√©couper (gauche/droite),
   * d√©terminer le type (RECTO/VERSO) via `HeaderDetector` **en s‚Äôappuyant r√©ellement** sur `determine_scan_type_and_order`,
   * renvoyer un r√©sultat **structur√© et directement exploitable**.
2. Gestion propre des temporaires :

   * `determine_scan_type_and_order` √©crit un fichier temporaire (`temp_right_path`).
   * Exigence : cr√©ation dans un r√©pertoire temporaire syst√®me (`tempfile`) + suppression en fin de traitement m√™me en cas d‚Äôerreur (try/finally).
3. R√©sultat attendu (contrat minimal) :

   * `type`: `"RECTO" | "VERSO" | "UNKNOWN"`
   * `pages`: dict `{"p1": ndarray, "p2": ..., "p3": ..., "p4": ...}` **si reconstruction compl√®te possible**
     ou a minima, le dict renvoy√© par `determine_scan_type_and_order` (RECTO contient p1/p4, VERSO contient p2/p3).
4. Robustesse :

   * si d√©tection en-t√™te √©choue (exception), renvoyer `UNKNOWN` + crops bruts, sans crash silencieux.

### Tests minimaux attendus

Sans introduire d‚Äôoutils lourds :

* **Test unitaire** (si pytest disponible) : mock du `HeaderDetector.detect_header()` pour forcer RECTO/VERSO et v√©rifier la structure.
* V√©rifier absence de fuite de fichier temporaire (au moins via appel dans un r√©pertoire temp contr√¥l√©).

### Crit√®res d‚Äôacceptation

* `process_scan()` renvoie un dict avec `type` et des pages coh√©rentes.
* En cas d‚Äôimage introuvable/illisible ‚Üí exception explicite inchang√©e.
* Pas de ‚Äúplaceholder logic‚Äù restant (ou strictement cantonn√© au cas UNKNOWN).

---

## Patch D ‚Äî CSV robuste et testable (`backend/students/management/commands/import_students.py` + nouveau service)

### Probl√®me actuel

* Parsing CSV dans la commande, logique m√™l√©e √† la DB (difficile √† tester proprement).
* Encodage `utf-8` (pas `utf-8-sig`) + BOM patch local.
* D√©limiteur ‚Äú;‚Äù forc√© (OK si sp√©c impos√©e) mais pas r√©ellement robuste.
* Validation d‚Äôen-t√™tes implicite.

### Exigences fonctionnelles

1. Extraire le parsing CSV dans un module d√©di√©, pur et testable :

   * ex : `backend/students/services/import_csv.py`
2. Fonction attendue (contrat) :

   * lecture fichier,
   * support `utf-8-sig`,
   * normalisation en-t√™tes,
   * d√©tection simple du s√©parateur si non impos√© (ou conserver `;` si c‚Äôest la norme Korrigo V1),
   * validation des champs requis : `INE`, `NOM`, `PRENOM` (et id√©alement `CLASSE`, `EMAIL` optionnels).
3. La commande `import_students` :

   * appelle le service pour obtenir une liste de dict normalis√©s,
   * puis ex√©cute la logique `update_or_create` comme actuellement (minimum),
   * conserve les compteurs success/errors et logs.

### Tests minimaux attendus

* Test unitaire du service de parsing CSV :

  * utilise un CSV fixture (si existante dans le repo) ou un CSV ‚Äúinline‚Äù cr√©√© en temp.
  * v√©rifie que :

    * BOM ne casse pas le premier header,
    * les champs sont trim,
    * lignes vides ignor√©es,
    * champs requis manquants ‚Üí erreur ou marquage explicite (selon choix minimal).
* (Optionnel mais utile) test d‚Äôint√©gration Django minimal : pas requis dans le scope minimal.

### Crit√®res d‚Äôacceptation

* Le parsing est testable ind√©pendamment de Django ORM.
* La commande continue de fonctionner avec le format annonc√©.
* Les erreurs CSV sont plus explicites (ligne, champ manquant, etc.).

---

## 4) Param√®tres d‚Äôenvironnement (contrats attendus)

### Production / E2E

* `DJANGO_ENV` :

  * `production` active les garde-fous (DEBUG interdit)
  * `development` / d√©faut : comportement dev
* `DEBUG` :

  * reconnu, mais **interdit en prod**
* `SSL_ENABLED` :

  * inchang√© (d√©j√† pr√©sent)
* `ALLOWED_HOSTS`, `CORS_ALLOWED_ORIGINS`, `RATELIMIT_ENABLE` :

  * inchang√©s

---

## 5) Plan de validation (checklist de recette)

### A. Config

* [ ] Lancer avec `DJANGO_ENV=production` sans `DEBUG` : DEBUG False.
* [ ] Lancer avec `DJANGO_ENV=production` et `DEBUG=True` : crash explicite.
* [ ] Lancer en dev : fonctionne comme avant.

### B. URLs

* [ ] `GET /api/health/` ‚Üí 200 OK
* [ ] `GET /api/schema/` ‚Üí OK
* [ ] `GET /api/docs/` ‚Üí OK
* [ ] `POST /api/login/` ‚Üí OK (si user test)
* [ ] En prod : pas de route static media servie par Django

### C. Split

* [ ] Appel `process_scan(path)` renvoie `type` + pages attendues selon mock detect_header.
* [ ] Pas de fichier temporaire r√©siduel.

### D. CSV

* [ ] Test unitaire parsing passe.
* [ ] Commande sur CSV r√©el : succ√®s, erreurs coh√©rentes.

---

## 6) Livrables attendus (format ‚Äúdiff/patch‚Äù)

Pour chaque patch (A‚ÜíD), vous attendez ensuite un **diff unifi√©** (`git diff`) avec :

* liste exacte des fichiers modifi√©s/ajout√©s,
* modifications minimales,
* tests ajout√©s (au moins pour le parsing CSV et/ou split via mock),
* aucune modification hors scope.

---

## 7) Points de d√©cision (√† trancher ‚Äúminimalement‚Äù avant d‚Äô√©crire les diffs)

1. **URL grading** : peut-on d√©placer `grading.urls` sous `/api/grading/` sans casser les consumers ?

   * Si oui : c‚Äôest la correction la plus propre et minimale c√¥t√© collisions.
   * Si non : il faudra conserver `/api/` mais s‚Äôassurer que `grading.urls` n‚Äôa pas de patterns ‚Äúcatch-all‚Äù.

2. **CSV s√©parateur** : Korrigo V1 impose-t-il strictement `;` ?

   * Si oui : on conserve `;` par d√©faut, d√©tection optionnelle uniquement si besoin.
   * Si non : auto-d√©tection simple (virgule/point-virgule/tab).

---

Ci-dessous : **(A) cahier des charges ‚Äúpatch minimal‚Äù** puis **(B) patch diff exact (unified diff, ligne par ligne)**, strictement sur le p√©rim√®tre demand√© :

* rendre **split** r√©ellement fonctionnel (service A3),
* corriger **`urls.py`** (notamment **pr√©fixe grading**),
* s√©curiser **`DEBUG`** en prod,
* rendre l‚Äôimport **CSV** **robuste et testable** (**s√©parateur virgule** par d√©faut),
* rester align√© ‚Äúmissions Korrigo V1‚Äù (MVP, pas de refonte).

---

## A) Cahier des charges minimal (sp√©cifications patch)

### 1) S√©curisation `DEBUG` en production (`backend/core/settings.py`)

**Objectif :** emp√™cher tout d√©marrage en prod avec un `DEBUG=True` accidentel, tout en gardant un comportement souple en dev.

**Exigences :**

* Introduire `DJANGO_ENV` **t√¥t** (au d√©but du fichier), en minuscules.
* Comportement :

  * si `DJANGO_ENV=production` :

    * `DEBUG` doit √™tre **False par d√©faut** si variable `DEBUG` absente,
    * si `DEBUG=true` est explicitement fourni ‚áí **raise ValueError** (fail fast).
  * sinon (dev) : conserver la compatibilit√© actuelle (`DEBUG` par d√©faut √† True).
* Adapter les gardes existantes qui testent `os.environ.get("DJANGO_ENV")` pour utiliser `DJANGO_ENV`.

**Non-objectifs :**

* Ne pas restructurer le reste du settings (CSP, CORS, etc.), uniquement patch minimal.

---

### 2) Correction et rationalisation des routes (`backend/core/urls.py`)

**Objectif :**

* corriger l‚Äôint√©gration `grading` via un **pr√©fixe d√©di√©** (vous avez demand√© ‚Äúpour le grading choisissez le pr√©fix‚Äù),
* √©viter de servir les m√©dias via Django en prod.

**Exigences :**

* Remplacer :

  * `path('api/', include('grading.urls'))`
  * par **`path('api/grading/', include('grading.urls'))`**
* Servir `MEDIA_URL` via `static()` **uniquement en DEBUG** :

  * En prod, ce sera Nginx/serveur web qui servira `/media/`.
* Ne pas changer les autres endpoints ni leur structure (missions Korrigo V1).

---

### 3) ‚ÄúSplit‚Äù r√©ellement fonctionnel (`backend/processing/services/splitter.py`)

**Objectif :** passer d‚Äôun placeholder √† un service exploitable en prod (sans refacto lourde).

**Exigences minimales :**

* `process_scan(image_path)` doit :

  * charger l‚Äôimage,
  * la couper en 2 moiti√©s,
  * ex√©cuter la d√©tection d‚Äôen-t√™te (via `HeaderDetector.detect_header`) sur la moiti√© **droite**,
  * retourner une structure **stable** :

    * `type`: `RECTO|VERSO`,
    * `left_page`, `right_page`,
    * `has_header` (bool),
    * et **`pages`** (mapping `p1/p4` ou `p2/p3`) conforme √† `determine_scan_type_and_order`.
* Gestion safe du fichier temporaire :

  * usage de `tempfile.NamedTemporaryFile(delete=False)` pour fournir un chemin au d√©tecteur,
  * suppression du fichier temporaire en `finally` (pas de fuite).
* Aucune d√©pendance nouvelle hors stdlib.

**Non-objectifs :**

* Ne pas impl√©menter un pipeline PDF complet ni √©crire sur disque les pages finales ; on rend le service **appelable** et coh√©rent.

---

### 4) Import CSV robuste et testable (`backend/students/management/commands/import_students.py` + nouveau service + tests)

**Objectif :** sortir la logique m√©tier du `Command.handle()` afin de pouvoir la tester sans lancer la commande, et fiabiliser l‚Äôimport.

**Exigences :**

* **S√©parateur : virgule (`,`) par d√©faut.**
* Ajouter un module de service (nouveau fichier) qui :

  * d√©tecte le s√©parateur si besoin (`csv.Sniffer`) mais **privil√©gie la virgule**,
  * g√®re BOM (`utf-8-sig`),
  * normalise les ent√™tes (trim + upper),
  * valide les champs requis : `INE`, `NOM`, `PRENOM` (classe/email optionnels),
  * retourne un objet r√©sultat testable (compteurs + erreurs structur√©es).
* La commande Django devient un simple ‚Äúwrapper‚Äù :

  * v√©rifie l‚Äôexistence du fichier,
  * appelle le service,
  * affiche un r√©sum√© final.
* Ajouter des tests (pytest / pytest-django compatible) couvrant :

  * import nominal (cr√©ation),
  * r√©-import (update),
  * ligne invalide (skip + erreur structur√©e).

**Non-objectifs :**

* Ne pas ajouter de d√©pendances externes, ne pas changer le mod√®le Student.

---

## B) Patch diff exact (unified diff)

> **Note** : je fournis ici un patch ‚Äúgit apply‚Äù standard.
> Il cr√©e 2 nouveaux fichiers (`csv_import.py` + tests) et modifie uniquement les 4 fichiers du p√©rim√®tre.

---

### 1) `backend/core/settings.py` ‚Äî DEBUG prod safe + DJANGO_ENV centralis√©

```diff
diff --git a/backend/core/settings.py b/backend/core/settings.py
index 1111111..2222222 100644
--- a/backend/core/settings.py
+++ b/backend/core/settings.py
@@ -1,11 +1,26 @@
 import os
 import dj_database_url
 from pathlib import Path
 
 BASE_DIR = Path(__file__).resolve().parent.parent
 
+# Environment
+DJANGO_ENV = os.environ.get("DJANGO_ENV", "development").lower()
+
 # Security: No dangerous defaults in production
 SECRET_KEY = os.environ.get("SECRET_KEY")
 if not SECRET_KEY:
-    if os.environ.get("DJANGO_ENV") == "production":
+    if DJANGO_ENV == "production":
         raise ValueError("SECRET_KEY environment variable must be set in production")
     # Development fallback only
     SECRET_KEY = "django-insecure-dev-only-" + "x" * 50
 
-DEBUG = os.environ.get("DEBUG", "True").lower() == "true"
+_debug_env = os.environ.get("DEBUG")
+if DJANGO_ENV == "production":
+    # Safe default in production: DEBUG must be False unless explicitly set,
+    # and we hard-fail if someone tries DEBUG=True.
+    DEBUG = (_debug_env or "False").lower() == "true"
+    if DEBUG:
+        raise ValueError("DEBUG must be False in production environment")
+else:
+    # Development-friendly default
+    DEBUG = (_debug_env or "True").lower() == "true"
 
 # ALLOWED_HOSTS: Explicit configuration required
 ALLOWED_HOSTS = os.environ.get("ALLOWED_HOSTS", "localhost,127.0.0.1").split(",")
-if "*" in ALLOWED_HOSTS and os.environ.get("DJANGO_ENV") == "production":
+if "*" in ALLOWED_HOSTS and DJANGO_ENV == "production":
     raise ValueError("ALLOWED_HOSTS cannot contain '*' in production")
@@ -143,10 +158,9 @@ RATELIMIT_USE_CACHE = 'default'
 
 # Enable/disable django-ratelimit via env (default: enabled)
 # Can be disabled for E2E testing environment only
 RATELIMIT_ENABLE = os.environ.get("RATELIMIT_ENABLE", "true").lower() == "true"
 
 # Production guard: prevent accidental rate limiting disable in production
-DJANGO_ENV = os.environ.get("DJANGO_ENV", "development")
 if DJANGO_ENV == "production" and not RATELIMIT_ENABLE:
     raise ValueError("RATELIMIT_ENABLE cannot be false in production environment")
```

---

### 2) `backend/core/urls.py` ‚Äî pr√©fixe grading + m√©dia uniquement en DEBUG

```diff
diff --git a/backend/core/urls.py b/backend/core/urls.py
index 3333333..4444444 100644
--- a/backend/core/urls.py
+++ b/backend/core/urls.py
@@ -1,7 +1,7 @@
 from django.contrib import admin
 from django.urls import path, include
 from django.conf import settings
 from django.conf.urls.static import static
 from core import views
 from drf_spectacular.views import SpectacularAPIView, SpectacularSwaggerView, SpectacularRedocView
 
 urlpatterns = [
     path('admin/', admin.site.urls),
     path('api/exams/', include('exams.urls')),
     path('api/copies/', include('exams.urls_copies')), # Mission 17
     path('api/students/', include('students.urls')), # Mission 18
     path('api/identification/', include('identification.urls')), # √âTAPE 1-2: OCR & Identification
-    path('api/', include('grading.urls')),  # √âtape 3: Annotations & Grading
+    path('api/grading/', include('grading.urls')),  # √âtape 3: Annotations & Grading (prefixed)
     path('api/login/', views.LoginView.as_view(), name='login'),
     path('api/logout/', views.LogoutView.as_view(), name='logout'),
     path('api/me/', views.UserDetailView.as_view(), name='user_detail'),
     path('api/settings/', views.GlobalSettingsView.as_view(), name='settings'),
     path('api/change-password/', views.ChangePasswordView.as_view(), name='change_password'),
     path('api/users/', views.UserListView.as_view(), name='user_list'),
     path('api/users/<int:pk>/', views.UserManageView.as_view(), name='user_manage'),
 ]
@@ -33,4 +33,7 @@ urlpatterns += [
         path('api/dev/seed/', seed_e2e_endpoint, name='seed_e2e'),
     ]
 
-urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)
+if settings.DEBUG:
+    # Only serve media via Django in dev. In production, serve via reverse proxy (Nginx).
+    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)
```

---

### 3) `backend/processing/services/splitter.py` ‚Äî split A3 r√©ellement exploitable

```diff
diff --git a/backend/processing/services/splitter.py b/backend/processing/services/splitter.py
index 5555555..6666666 100644
--- a/backend/processing/services/splitter.py
+++ b/backend/processing/services/splitter.py
@@ -1,6 +1,8 @@
 import cv2
 import numpy as np
+import os
+import tempfile
 from django.utils.translation import gettext_lazy as _
 from .vision import HeaderDetector
 
 class A3Splitter:
@@ -18,7 +20,7 @@ class A3Splitter:
     def process_scan(self, image_path: str):
         """
         D√©coupe une image A3 en deux A4 et d√©termine si c'est un Recto ou un Verso.
         
@@ -34,44 +36,53 @@ class A3Splitter:
                 'right_page': numpy.ndarray,
                 'has_header': bool
             }
         """
         image = cv2.imread(image_path)
         if image is None:
             raise ValueError(_("Impossible de lire l'image : ") + image_path)
 
-        height, width, _ = image.shape
+        height, width, _ = image.shape
         
         # D√©coupage vertical strict √† 50%
         mid_x = width // 2
         left_crop = image[:, :mid_x]
         right_crop = image[:, mid_x:]
 
-        # Sauvegarde temporaire pour la d√©tection (HeaderDetector attend un chemin)
-        # Optimisation: HeaderDetector pourrait accepter un ndarray directement.
-        # Pour ce MVP, on suppose que HeaderDetector a √©t√© refactoris√© ou on garde l'API path.
-        # Modifions HeaderDetector pour accepter une image en m√©moire si on pouvait, 
-        # mais respectons l'interface existante. Hack: sauvegarder temp.
-        
-        # Pour l'instant on r√©impl√©mente une logique simple ou on mock.
-        # Utilisons la logique "Right Half has Header => Recto"
-        
-        # Simuler la d√©tection sur la partie DROITE
-        # En prod, on passerait right_crop √† detector.detect_header_from_array(right_crop)
-        
-        # Placeholder logic: On assume que create_temp_file est g√©r√© ailleurs. 
-        # Ici on retourne les crops.
-        
-        return {
-            'left': left_crop,
-            'right': right_crop,
-            'width': width,
-            'height': height
-        }
+        # HeaderDetector attend un chemin : on √©crit temporairement la partie droite
+        tmp_path = None
+        try:
+            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
+                tmp_path = tmp.name
+
+            # D√©termine type + ordre logique (p1/p4 ou p2/p3)
+            order_data = self.determine_scan_type_and_order(
+                left_img=left_crop,
+                right_img=right_crop,
+                temp_right_path=tmp_path
+            )
+
+            return {
+                'type': order_data['type'],
+                'left_page': left_crop,
+                'right_page': right_crop,
+                'has_header': (order_data['type'] == 'RECTO'),
+                'pages': order_data['pages'],
+                'width': width,
+                'height': height,
+            }
+        finally:
+            if tmp_path and os.path.exists(tmp_path):
+                try:
+                    os.remove(tmp_path)
+                except OSError:
+                    # Best effort cleanup: do not hide main processing result
+                    pass
 
     def determine_scan_type_and_order(self, left_img, right_img, temp_right_path: str) -> dict:
         """
         D√©termine si le scan est Recto ou Verso en cherchant un en-t√™te √† droite.
```

---

### 4) CSV : extraction logique + virgule par d√©faut + tests

#### 4.1 Nouveau service : `backend/students/services/csv_import.py`

```diff
diff --git a/backend/students/services/csv_import.py b/backend/students/services/csv_import.py
new file mode 100644
index 0000000..7777777
--- /dev/null
+++ b/backend/students/services/csv_import.py
@@ -0,0 +1,178 @@
+from __future__ import annotations
+
+import csv
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, List, Optional, Tuple, Type
+
+from django.db import transaction
+
+
+REQUIRED_FIELDS = ("INE", "NOM", "PRENOM")
+OPTIONAL_FIELDS = ("CLASSE", "EMAIL")
+
+
+@dataclass
+class ImportErrorItem:
+    row: int
+    message: str
+    data: Dict[str, str] = field(default_factory=dict)
+
+
+@dataclass
+class ImportResult:
+    delimiter: str
+    created: int = 0
+    updated: int = 0
+    skipped: int = 0
+    errors: List[ImportErrorItem] = field(default_factory=list)
+
+
+def _normalize_key(key: str) -> str:
+    return (key or "").strip().upper()
+
+
+def _normalize_value(value: Optional[str]) -> str:
+    return (value or "").strip()
+
+
+def detect_delimiter(sample: str, default: str = ",") -> str:
+    """
+    Best-effort delimiter detection. We keep comma as the default separator,
+    but accept sniffed delimiters when the file clearly uses another one.
+    """
+    try:
+        dialect = csv.Sniffer().sniff(sample, delimiters=[",", ";", "\t"])
+        return dialect.delimiter or default
+    except Exception:
+        return default
+
+
+def read_rows_from_csv(fp, delimiter: Optional[str] = None) -> Tuple[str, Iterable[Dict[str, str]]]:
+    """
+    Returns (delimiter_used, iterator over raw rows).
+    """
+    # Read a small sample for delimiter sniffing, then rewind.
+    sample = fp.read(4096)
+    fp.seek(0)
+
+    delimiter_used = delimiter or detect_delimiter(sample, default=",")
+
+    reader = csv.DictReader(fp, delimiter=delimiter_used)
+
+    # Normalize BOM in first header if present
+    if reader.fieldnames:
+        reader.fieldnames = [fn.replace("\ufeff", "") if fn else fn for fn in reader.fieldnames]
+
+    return delimiter_used, reader
+
+
+def parse_students_csv(path: str, delimiter: str = ",") -> Tuple[ImportResult, List[Dict[str, str]]]:
+    """
+    Parse file into normalized rows without touching the DB.
+    """
+    result = ImportResult(delimiter=delimiter)
+    rows: List[Dict[str, str]] = []
+
+    # utf-8-sig handles BOM robustly
+    with open(path, "r", encoding="utf-8-sig", newline="") as f:
+        delimiter_used, reader = read_rows_from_csv(f, delimiter=delimiter)
+        result.delimiter = delimiter_used
+
+        for idx, row in enumerate(reader, start=1):
+            if not row:
+                result.skipped += 1
+                continue
+
+            normalized: Dict[str, str] = {}
+            for k, v in row.items():
+                nk = _normalize_key(k)
+                if not nk:
+                    continue
+                normalized[nk] = _normalize_value(v)
+
+            # Validate required fields
+            missing = [k for k in REQUIRED_FIELDS if not normalized.get(k)]
+            if missing:
+                result.skipped += 1
+                result.errors.append(
+                    ImportErrorItem(
+                        row=idx,
+                        message=f"Missing required fields: {', '.join(missing)}",
+                        data=normalized,
+                    )
+                )
+                continue
+
+            # Keep only known fields + required
+            cleaned = {
+                "INE": normalized.get("INE", ""),
+                "NOM": normalized.get("NOM", ""),
+                "PRENOM": normalized.get("PRENOM", ""),
+                "CLASSE": normalized.get("CLASSE", ""),
+                "EMAIL": normalized.get("EMAIL", ""),
+            }
+            rows.append(cleaned)
+
+    return result, rows
+
+
+def import_students_rows(rows: List[Dict[str, str]], student_model) -> ImportResult:
+    """
+    Apply rows to DB. Separated from parsing to keep it testable.
+    """
+    result = ImportResult(delimiter=",")
+
+    for i, r in enumerate(rows, start=1):
+        ine = r["INE"]
+        last_name = r["NOM"]
+        first_name = r["PRENOM"]
+        class_name = r.get("CLASSE", "")
+        email = r.get("EMAIL", "")
+
+        try:
+            with transaction.atomic():
+                obj, created = student_model.objects.update_or_create(
+                    ine=ine,
+                    defaults={
+                        "first_name": first_name,
+                        "last_name": last_name,
+                        "class_name": class_name,
+                        "email": email,
+                    },
+                )
+            if created:
+                result.created += 1
+            else:
+                result.updated += 1
+        except Exception as e:
+            result.errors.append(
+                ImportErrorItem(
+                    row=i,
+                    message=str(e),
+                    data=r,
+                )
+            )
+
+    return result
+
+
+def import_students_from_csv(path: str, student_model, delimiter: str = ",") -> ImportResult:
+    """
+    High-level helper: parse + import.
+    """
+    parse_result, rows = parse_students_csv(path, delimiter=delimiter)
+    db_result = import_students_rows(rows, student_model=student_model)
+
+    # Merge results (delimiter + skipped/errors from parsing + created/updated/errors from DB)
+    merged = ImportResult(delimiter=parse_result.delimiter)
+    merged.created = db_result.created
+    merged.updated = db_result.updated
+    merged.skipped = parse_result.skipped
+    merged.errors = [*parse_result.errors, *db_result.errors]
+    return merged
```

---

#### 4.2 `backend/students/management/commands/import_students.py` ‚Äî devient wrapper + virgule

```diff
diff --git a/backend/students/management/commands/import_students.py b/backend/students/management/commands/import_students.py
index 8888888..9999999 100644
--- a/backend/students/management/commands/import_students.py
+++ b/backend/students/management/commands/import_students.py
@@ -1,78 +1,48 @@
 from django.core.management.base import BaseCommand
 from students.models import Student
-import csv
 import os
+from students.services.csv_import import import_students_from_csv
 
 class Command(BaseCommand):
-    help = 'Imports students from a CSV file (Format: INE;NOM;PRENOM;CLASSE;EMAIL)'
+    help = 'Imports students from a CSV file (Format: INE,NOM,PRENOM,CLASSE,EMAIL)'
 
     def add_arguments(self, parser):
         parser.add_argument('csv_file', type=str, help='Path to the CSV file')
 
     def handle(self, *args, **options):
         csv_file_path = options['csv_file']
 
         if not os.path.exists(csv_file_path):
             self.stdout.write(self.style.ERROR(f'File not found: {csv_file_path}'))
             return
 
         self.stdout.write(f'Importing students from {csv_file_path}...')
 
-        success_count = 0
-        error_count = 0
-
         try:
-            with open(csv_file_path, 'r', encoding='utf-8') as f:
-                # Detect delimiter if needed, or assume ';' based on spec
-                reader = csv.DictReader(f, delimiter=';')
-                
-                # Check for BOM just in case
-                if reader.fieldnames and reader.fieldnames[0].startswith('\ufeff'):
-                     reader.fieldnames[0] = reader.fieldnames[0].replace('\ufeff', '')
-                
-                # Expected Columns: INE, NOM, PRENOM, CLASSE, EMAIL
-                # Allow case-insensitive matching or standard names
-                
-                for row_idx, row in enumerate(reader, start=1):
-                    # Normalized keys
-                    row_clean = {k.strip().upper(): v.strip() for k, v in row.items() if k}
-                    
-                    ine = row_clean.get('INE')
-                    last_name = row_clean.get('NOM')
-                    first_name = row_clean.get('PRENOM')
-                    class_name = row_clean.get('CLASSE')
-                    email = row_clean.get('EMAIL', '')
-
-                    if not ine or not last_name or not first_name:
-                        self.stdout.write(self.style.WARNING(f'Skipping Row {row_idx}: Missing required fields (INE/NOM/PRENOM) - Data: {row}'))
-                        error_count += 1
-                        continue
-
-                    try:
-                        student, created = Student.objects.update_or_create(
-                            ine=ine,
-                            defaults={
-                                'first_name': first_name,
-                                'last_name': last_name,
-                                'class_name': class_name,
-                                'email': email
-                            }
-                        )
-                        action = "Created" if created else "Updated"
-                        # self.stdout.write(f'{action}: {student}') # Verbose
-                        success_count += 1
-                    except Exception as e:
-                        self.stdout.write(self.style.ERROR(f'Error Row {row_idx}: {e}'))
-                        error_count += 1
-
-            self.stdout.write(self.style.SUCCESS(f'Import Complete. Success: {success_count}, Errors: {error_count}'))
-
+            result = import_students_from_csv(csv_file_path, student_model=Student, delimiter=',')
+            self.stdout.write(
+                self.style.SUCCESS(
+                    "Import Complete. "
+                    f"Created: {result.created}, Updated: {result.updated}, "
+                    f"Skipped: {result.skipped}, Errors: {len(result.errors)}, "
+                    f"Delimiter: '{result.delimiter}'"
+                )
+            )
+            if result.errors:
+                for err in result.errors[:50]:
+                    self.stdout.write(self.style.WARNING(f"Row {err.row}: {err.message}"))
         except Exception as e:
-             self.stdout.write(self.style.ERROR(f'Failed to read CSV: {e}'))
+            self.stdout.write(self.style.ERROR(f'Import failed: {e}'))
```

---

#### 4.3 Tests : `backend/students/tests/test_import_students_csv.py`

```diff
diff --git a/backend/students/tests/test_import_students_csv.py b/backend/students/tests/test_import_students_csv.py
new file mode 100644
index 0000000..aaaaaaa
--- /dev/null
+++ b/backend/students/tests/test_import_students_csv.py
@@ -0,0 +1,74 @@
+import pytest
+
+from students.models import Student
+from students.services.csv_import import import_students_from_csv
+
+
+@pytest.mark.django_db
+def test_import_students_from_csv_creates_and_updates(tmp_path):
+    p = tmp_path / "students.csv"
+    p.write_text(
+        "INE,NOM,PRENOM,CLASSE,EMAIL\n"
+        "1234A,Dupont,Jean,T1,jean.dupont@example.com\n"
+        "5678B,Martin,Lea,T2,lea.martin@example.com\n",
+        encoding="utf-8",
+    )
+
+    res1 = import_students_from_csv(str(p), student_model=Student, delimiter=",")
+    assert res1.created == 2
+    assert res1.updated == 0
+    assert res1.skipped == 0
+    assert len(res1.errors) == 0
+
+    # Update same INE with different values
+    p.write_text(
+        "INE,NOM,PRENOM,CLASSE,EMAIL\n"
+        "1234A,Dupont,Jean,T3,jean.dupont@example.com\n",
+        encoding="utf-8",
+    )
+    res2 = import_students_from_csv(str(p), student_model=Student, delimiter=",")
+    assert res2.created == 0
+    assert res2.updated == 1
+    assert res2.skipped == 0
+    assert len(res2.errors) == 0
+
+
+@pytest.mark.django_db
+def test_import_students_from_csv_skips_invalid_rows(tmp_path):
+    p = tmp_path / "students_invalid.csv"
+    p.write_text(
+        "INE,NOM,PRENOM,CLASSE,EMAIL\n"
+        ",Dupont,Jean,T1,jean.dupont@example.com\n"
+        "9999C,,Sarah,T1,sarah@example.com\n"
+        "1111D,Valid,Student,T1,valid@example.com\n",
+        encoding="utf-8",
+    )
+
+    res = import_students_from_csv(str(p), student_model=Student, delimiter=",")
+    assert res.created == 1
+    assert res.updated == 0
+    assert res.skipped == 2
+    assert len(res.errors) == 2
```

---

## Points d‚Äôint√©gration / v√©rifications (mini checklist)

1. **URLs**

* V√©rifier rapidement que `grading.urls` ne ‚Äúdouble-pr√©fixe‚Äù pas d√©j√† (ex: s‚Äôil contient `path('grading/...')`).

  * Avec le patch : base = `/api/grading/‚Ä¶`

2. **Prod safety**

* D√©marrage en prod (`DJANGO_ENV=production`) :

  * sans `DEBUG` ‚áí `DEBUG=False` OK
  * avec `DEBUG=true` ‚áí crash volontaire (s√©curit√©)

3. **CSV**

* Le service accepte par d√©faut `delimiter=","` (exigence),
* il est testable isol√©ment (parse + import),
* erreurs structur√©es + compteurs d√©terministes.

4. **Split**

* `process_scan()` n‚Äôest plus un placeholder : il renvoie `type/has_header/pages` coh√©rents et nettoie le temporaire.




