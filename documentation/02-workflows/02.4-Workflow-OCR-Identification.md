# 02.4 - Workflow OCR et Identification des Copies

**Projet** : Korrigo - SystÃ¨me de Correction d'Examens
**Version** : 2.0 (PRD-19 - OCR Multi-layer)
**Date** : 3 FÃ©vrier 2026
**Auteur** : **Alaeddine BEN RHOUMA**

---

## ðŸŽ¯ Objectif

L'identification des copies consiste Ã  **associer chaque copie anonyme scannÃ©e Ã  un Ã©tudiant** en utilisant l'OCR (Optical Character Recognition) pour extraire le nom et la date de naissance depuis l'en-tÃªte de la copie, puis Ã  matcher ces informations avec la liste des Ã©tudiants (CSV).

### Ã‰volution PRD-19

**Avant (PRD-18)** :
- OCR simple avec **Tesseract uniquement**
- Taux de rÃ©ussite : **~30-40%** sur CMEN v2 (Ã©criture manuscrite)
- Mode binaire : AUTO ou MANUAL

**AprÃ¨s (PRD-19)** :
- **OCR Multi-layer** : Tesseract + EasyOCR + PaddleOCR
- **Consensus voting** : AgrÃ©gation des rÃ©sultats de 3 moteurs
- **Preprocessing avancÃ©** : 4 variantes d'images (deskew, binarization, CLAHE, morpho)
- Taux de rÃ©ussite attendu : **>70% AUTO + 20% SEMI-AUTO**
- Mode ternaire : **AUTO / SEMI-AUTO / MANUAL**

---

## ðŸ“Š Vue d'Ensemble du Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Ã‰TAPE 1: DÃ‰TECTION HEADER                   â”‚
â”‚  Vision.py â†’ DÃ©tecter la zone d'en-tÃªte (nom + date)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Ã‰TAPE 2: PREPROCESSING (4 VARIANTES)                 â”‚
â”‚  â€¢ Deskew (correction inclinaison)                             â”‚
â”‚  â€¢ Binarization (Otsu threshold)                               â”‚
â”‚  â€¢ CLAHE (amÃ©lioration contraste)                              â”‚
â”‚  â€¢ Morphological cleanup                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Ã‰TAPE 3: OCR MULTI-LAYER (3 MOTEURS Ã— 4 VARIANTES)      â”‚
â”‚  â€¢ Tesseract (PSM 6, French)                                   â”‚
â”‚  â€¢ EasyOCR (French + English)                                  â”‚
â”‚  â€¢ PaddleOCR (French)                                          â”‚
â”‚  = 12 rÃ©sultats OCR au total                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Ã‰TAPE 4: FUZZY MATCHING CONTRE CSV                    â”‚
â”‚  Pour chaque rÃ©sultat OCR:                                     â”‚
â”‚  â€¢ Parser nom + date de naissance                              â”‚
â”‚  â€¢ Fuzzy match (Jaccard similarity) contre liste CSV          â”‚
â”‚  â€¢ Score = 0.6 Ã— match_nom + 0.4 Ã— match_date                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Ã‰TAPE 5: CONSENSUS VOTING                          â”‚
â”‚  â€¢ AgrÃ©ger les scores par Ã©tudiant                             â”‚
â”‚  â€¢ PondÃ©rer par confidence OCR                                 â”‚
â”‚  â€¢ Retourner TOP-5 candidats                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                       â”‚            â”‚
           â–¼                       â–¼            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ AUTO        â”‚        â”‚ SEMI-AUTO   â”‚  â”‚ MANUAL   â”‚
    â”‚ conf > 0.7  â”‚        â”‚ 0.4-0.7     â”‚  â”‚ < 0.4    â”‚
    â”‚ â†’ Assigner  â”‚        â”‚ â†’ Top-5 UI  â”‚  â”‚ â†’ Search â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ” Ã‰tape 1 : DÃ©tection de la Zone d'En-TÃªte

### Objectif

Localiser prÃ©cisÃ©ment la **zone d'en-tÃªte** contenant les informations Ã©tudiant (nom, prÃ©nom, date de naissance) dans la premiÃ¨re page de chaque copie.

### ImplÃ©mentation

**Fichier** : `backend/processing/services/vision.py`

```python
import cv2
import numpy as np

class HeaderDetector:
    """DÃ©tecteur d'en-tÃªte de copie."""

    def __init__(self):
        self.header_height_ratio = 0.20  # 20% du haut de la page
        self.min_text_density = 0.1      # DensitÃ© minimale de texte

    def detect_header(self, page_image: np.ndarray) -> np.ndarray | None:
        """
        DÃ©tecter la zone d'en-tÃªte dans une page.

        Args:
            page_image: Image de la page (numpy array)

        Returns:
            Crop de l'en-tÃªte ou None si non dÃ©tectÃ©
        """
        h, w = page_image.shape[:2]

        # 1. DÃ©finir zone de recherche (20% du haut)
        search_height = int(h * self.header_height_ratio)
        search_region = page_image[:search_height, :]

        # 2. Convertir en niveaux de gris
        if len(search_region.shape) == 3:
            gray = cv2.cvtColor(search_region, cv2.COLOR_BGR2GRAY)
        else:
            gray = search_region

        # 3. Binarisation
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        # 4. DÃ©tecter contours (zones de texte)
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return None

        # 5. Fusionner contours proches (grouper texte)
        boxes = [cv2.boundingRect(c) for c in contours]
        boxes = self._merge_close_boxes(boxes, horizontal_threshold=50, vertical_threshold=20)

        # 6. SÃ©lectionner la plus grande zone (header)
        if not boxes:
            return None

        # Trouver bounding box englobant
        x_min = min(b[0] for b in boxes)
        y_min = min(b[1] for b in boxes)
        x_max = max(b[0] + b[2] for b in boxes)
        y_max = max(b[1] + b[3] for b in boxes)

        # 7. Ajouter marges
        margin = 10
        x_min = max(0, x_min - margin)
        y_min = max(0, y_min - margin)
        x_max = min(w, x_max + margin)
        y_max = min(search_height, y_max + margin)

        # 8. Extraire crop
        header_crop = page_image[y_min:y_max, x_min:x_max]

        # 9. VÃ©rifier densitÃ© de texte
        if self._check_text_density(header_crop):
            return header_crop

        return None

    def _merge_close_boxes(self, boxes, horizontal_threshold=50, vertical_threshold=20):
        """Fusionner les boxes proches pour grouper le texte."""
        if not boxes:
            return []

        # Trier par position verticale
        boxes = sorted(boxes, key=lambda b: b[1])

        merged = []
        current_group = [boxes[0]]

        for box in boxes[1:]:
            x, y, w, h = box
            prev_x, prev_y, prev_w, prev_h = current_group[-1]

            # VÃ©rifier proximitÃ© verticale et horizontale
            if (abs(y - prev_y) < vertical_threshold and
                abs(x - (prev_x + prev_w)) < horizontal_threshold):
                current_group.append(box)
            else:
                # Fusionner groupe prÃ©cÃ©dent
                merged.append(self._merge_boxes(current_group))
                current_group = [box]

        # Fusionner dernier groupe
        if current_group:
            merged.append(self._merge_boxes(current_group))

        return merged

    def _merge_boxes(self, boxes):
        """Fusionner plusieurs boxes en une seule."""
        x_min = min(b[0] for b in boxes)
        y_min = min(b[1] for b in boxes)
        x_max = max(b[0] + b[2] for b in boxes)
        y_max = max(b[1] + b[3] for b in boxes)
        return (x_min, y_min, x_max - x_min, y_max - y_min)

    def _check_text_density(self, image: np.ndarray) -> bool:
        """VÃ©rifier que l'image contient suffisamment de texte."""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        text_pixels = np.sum(binary > 0)
        total_pixels = binary.size
        density = text_pixels / total_pixels

        return density >= self.min_text_density
```

### Exemple de DÃ©tection

```python
# Utilisation
detector = HeaderDetector()
page_image = cv2.imread("copy_page_1.jpg")

header_region = detector.detect_header(page_image)

if header_region is not None:
    cv2.imwrite("header_detected.jpg", header_region)
    print(f"Header detected: {header_region.shape}")
else:
    print("No header detected")
```

---

## ðŸ–¼ï¸ Ã‰tape 2 : Preprocessing AvancÃ© (4 Variantes)

### Objectif

GÃ©nÃ©rer **4 variantes prÃ©traitÃ©es** de l'image d'en-tÃªte pour maximiser les chances de succÃ¨s de l'OCR, car chaque moteur OCR rÃ©agit diffÃ©remment selon le prÃ©traitement.

### ImplÃ©mentation

**Fichier** : `backend/processing/services/ocr_engine.py`

```python
import cv2
import numpy as np

class ImagePreprocessor:
    """PrÃ©traitement avancÃ© d'images pour OCR robuste."""

    def preprocess_variants(self, image: np.ndarray) -> list[np.ndarray]:
        """
        GÃ©nÃ©rer 4 variantes prÃ©traitÃ©es de l'image.

        Returns:
            [variant_0_deskew, variant_1_clahe, variant_2_morph, variant_3_contrast]
        """
        variants = []

        # Variante 0: Deskew + Binarization Otsu
        deskewed = self._deskew(image)
        binary = self._binarize_otsu(deskewed)
        variants.append(binary)

        # Variante 1: Denoising + CLAHE (existing method)
        denoised = cv2.fastNlMeansDenoising(image)
        clahe_enhanced = self._apply_clahe(denoised)
        variants.append(clahe_enhanced)

        # Variante 2: Morphological cleanup
        morph_cleaned = self._morphological_cleanup(image)
        variants.append(morph_cleaned)

        # Variante 3: Contrast stretching
        stretched = self._contrast_stretch(image)
        variants.append(stretched)

        return variants

    def _deskew(self, image: np.ndarray) -> np.ndarray:
        """
        Corriger l'inclinaison de l'image (deskew).

        DÃ©tecte l'angle d'inclinaison et applique une rotation.
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image

        # DÃ©tecter contours
        coords = np.column_stack(np.where(gray > 0))

        if coords.size == 0:
            return image

        # Calculer angle avec minAreaRect
        angle = cv2.minAreaRect(coords)[-1]

        # Normaliser angle
        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle

        # Appliquer rotation
        (h, w) = image.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated = cv2.warpAffine(
            image, M, (w, h),
            flags=cv2.INTER_CUBIC,
            borderMode=cv2.BORDER_REPLICATE
        )

        return rotated

    def _binarize_otsu(self, image: np.ndarray) -> np.ndarray:
        """Binarisation avec mÃ©thode Otsu."""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        return binary

    def _apply_clahe(self, image: np.ndarray) -> np.ndarray:
        """AmÃ©lioration du contraste avec CLAHE."""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        return enhanced

    def _morphological_cleanup(self, image: np.ndarray) -> np.ndarray:
        """Nettoyage morphologique (remove noise, fill gaps)."""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image

        # Binarization
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        # Morphological operations
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))

        # Opening (remove small noise)
        opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)

        # Closing (fill small gaps)
        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=1)

        return closing

    def _contrast_stretch(self, image: np.ndarray) -> np.ndarray:
        """Ã‰tirement du contraste (histogram stretching)."""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image

        # Normaliser entre 0-255
        normalized = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)

        return normalized
```

### Visualisation des Variantes

```python
# Exemple d'utilisation
preprocessor = ImagePreprocessor()
header_image = cv2.imread("header.jpg")

variants = preprocessor.preprocess_variants(header_image)

# Sauvegarder les variantes
for idx, variant in enumerate(variants):
    cv2.imwrite(f"variant_{idx}.jpg", variant)

# Variant 0: Deskew + Otsu â†’ Meilleur pour Tesseract
# Variant 1: CLAHE â†’ Meilleur pour EasyOCR
# Variant 2: Morpho â†’ Meilleur pour texte bruyant
# Variant 3: Contrast â†’ Meilleur pour texte lÃ©ger
```

---

## ðŸ¤– Ã‰tape 3 : OCR Multi-Layer (3 Moteurs)

### Architecture

**3 moteurs OCR Ã— 4 variantes = 12 rÃ©sultats OCR**

```python
class MultiLayerOCR:
    """OCR multi-layer avec consensus voting."""

    def __init__(self):
        # Tesseract
        self.tesseract = TesseractOCR()

        # EasyOCR (charge modÃ¨les au dÃ©marrage)
        import easyocr
        self.easyocr_reader = easyocr.Reader(['fr', 'en'], gpu=False)

        # PaddleOCR
        from paddleocr import PaddleOCR
        self.paddleocr = PaddleOCR(lang='fr', use_angle_cls=True, use_gpu=False)

    def extract_text_with_candidates(
        self,
        header_image: np.ndarray,
        csv_students: list[Student]
    ) -> OCRCandidates:
        """
        Pipeline complet: OCR + Matching + Voting.

        Returns:
            OCRCandidates(
                top_candidates=[...],  # Top-5 Ã©tudiants
                ocr_mode='AUTO' | 'SEMI_AUTO' | 'MANUAL'
            )
        """
        # 1. Preprocessing
        preprocessor = ImagePreprocessor()
        variants = preprocessor.preprocess_variants(header_image)

        # 2. Run OCR sur toutes les variantes
        ocr_results = self._run_all_ocr_engines(variants)

        # 3. Fuzzy matching + Voting
        top_candidates = self._consensus_vote(ocr_results, csv_students)

        # 4. DÃ©terminer mode
        if top_candidates and top_candidates[0].confidence > 0.7:
            ocr_mode = 'AUTO'
        elif top_candidates and top_candidates[0].confidence > 0.4:
            ocr_mode = 'SEMI_AUTO'
        else:
            ocr_mode = 'MANUAL'

        return OCRCandidates(
            top_candidates=top_candidates[:5],  # Top-5
            ocr_mode=ocr_mode
        )

    def _run_all_ocr_engines(self, preprocessed_images: list[np.ndarray]) -> list[OCRCandidate]:
        """
        ExÃ©cuter les 3 moteurs OCR sur les 4 variantes.

        Returns:
            Liste de 12 OCRCandidate (3 engines Ã— 4 variants)
        """
        candidates = []

        for variant_idx, img in enumerate(preprocessed_images):
            # 1. Tesseract
            tess_text, tess_conf = self._ocr_tesseract(img)
            candidates.append(OCRCandidate(
                engine='tesseract',
                variant=variant_idx,
                text=tess_text,
                confidence=tess_conf
            ))

            # 2. EasyOCR
            easy_text, easy_conf = self._ocr_easyocr(img)
            candidates.append(OCRCandidate(
                engine='easyocr',
                variant=variant_idx,
                text=easy_text,
                confidence=easy_conf
            ))

            # 3. PaddleOCR
            paddle_text, paddle_conf = self._ocr_paddleocr(img)
            candidates.append(OCRCandidate(
                engine='paddleocr',
                variant=variant_idx,
                text=paddle_text,
                confidence=paddle_conf
            ))

        return candidates

    def _ocr_tesseract(self, image: np.ndarray) -> tuple[str, float]:
        """OCR avec Tesseract."""
        import pytesseract

        # PSM 6 = Assume a single uniform block of text
        custom_config = r'--oem 3 --psm 6 -l fra'

        data = pytesseract.image_to_data(
            image,
            config=custom_config,
            output_type=pytesseract.Output.DICT
        )

        # Extraire texte + confidence
        text_parts = []
        confidences = []

        for i, conf in enumerate(data['conf']):
            if conf > 0:  # Ignorer rÃ©sultats avec conf = -1
                text_parts.append(data['text'][i])
                confidences.append(conf)

        text = ' '.join(text_parts)
        avg_confidence = np.mean(confidences) / 100.0 if confidences else 0.0

        return text, avg_confidence

    def _ocr_easyocr(self, image: np.ndarray) -> tuple[str, float]:
        """OCR avec EasyOCR."""
        results = self.easyocr_reader.readtext(image)

        # Format: [(bbox, text, confidence), ...]
        text_parts = [r[1] for r in results]
        confidences = [r[2] for r in results]

        text = ' '.join(text_parts)
        avg_confidence = np.mean(confidences) if confidences else 0.0

        return text, avg_confidence

    def _ocr_paddleocr(self, image: np.ndarray) -> tuple[str, float]:
        """OCR avec PaddleOCR."""
        results = self.paddleocr.ocr(image, cls=True)

        if not results or not results[0]:
            return '', 0.0

        # Format: [[bbox, (text, confidence)], ...]
        text_parts = []
        confidences = []

        for line in results[0]:
            text, conf = line[1]
            text_parts.append(text)
            confidences.append(conf)

        text = ' '.join(text_parts)
        avg_confidence = np.mean(confidences) if confidences else 0.0

        return text, avg_confidence
```

---

## ðŸ§® Ã‰tape 4 : Fuzzy Matching Contre CSV

### Parsing du Texte OCR

```python
import re
from datetime import datetime

def parse_ocr_text(ocr_text: str) -> tuple[str | None, str | None]:
    """
    Parser le texte OCR pour extraire nom + date de naissance.

    Args:
        ocr_text: "DUPONT Jean 15/05/2008" ou "Jean Dupont 15-05-2008"

    Returns:
        (nom_complet, date_naissance)
        Ex: ("Jean Dupont", "15/05/2008")
    """
    # 1. Nettoyer le texte
    cleaned = ocr_text.strip().upper()

    # 2. Extraire date (patterns courants)
    date_patterns = [
        r'(\d{1,2}[/-]\d{1,2}[/-]\d{4})',  # 15/05/2008 ou 15-05-2008
        r'(\d{4}[/-]\d{1,2}[/-]\d{1,2})',  # 2008/05/15
        r'(\d{1,2}\s+\w+\s+\d{4})',         # 15 Mai 2008
    ]

    date_str = None
    for pattern in date_patterns:
        match = re.search(pattern, cleaned)
        if match:
            date_str = match.group(1)
            # Retirer date du texte
            cleaned = cleaned.replace(date_str, '').strip()
            break

    # Normaliser date
    if date_str:
        date_str = normalize_date(date_str)

    # 3. Nom = reste du texte (aprÃ¨s suppression date)
    name = cleaned.strip()

    return name, date_str


def normalize_date(date_str: str) -> str:
    """
    Normaliser une date au format DD/MM/YYYY.

    Exemples:
        "15-05-2008" â†’ "15/05/2008"
        "2008/05/15" â†’ "15/05/2008"
        "15 Mai 2008" â†’ "15/05/2008"
    """
    # Essayer plusieurs formats
    formats = [
        '%d/%m/%Y', '%d-%m-%Y',
        '%Y/%m/%d', '%Y-%m-%d',
        '%d %B %Y', '%d %b %Y'
    ]

    for fmt in formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            return dt.strftime('%d/%m/%Y')
        except ValueError:
            continue

    # Si Ã©chec, retourner tel quel
    return date_str
```

### Fuzzy Matching

```python
from fuzzywuzzy import fuzz

def fuzzy_match_student(
    ocr_name: str,
    ocr_date: str,
    student: Student
) -> float:
    """
    Calculer score de matching entre OCR et Ã©tudiant.

    Score = 0.6 Ã— score_nom + 0.4 Ã— score_date

    Returns:
        Score entre 0.0 et 1.0
    """
    # 1. Score nom (Jaccard similarity + token sort)
    student_full_name = f"{student.first_name} {student.last_name}".upper()

    # Token sort ratio (insensible Ã  l'ordre)
    name_score = fuzz.token_sort_ratio(ocr_name, student_full_name) / 100.0

    # 2. Score date
    student_dob = student.date_of_birth.strftime('%d/%m/%Y')

    if ocr_date and ocr_date == student_dob:
        date_score = 1.0
    elif ocr_date:
        # Fuzzy match date (permet petites erreurs)
        date_score = fuzz.ratio(ocr_date, student_dob) / 100.0
    else:
        date_score = 0.0

    # 3. Score combinÃ©
    final_score = 0.6 * name_score + 0.4 * date_score

    return final_score
```

---

## ðŸ—³ï¸ Ã‰tape 5 : Consensus Voting

### Algorithme de Voting

```python
from collections import defaultdict

def consensus_vote(
    ocr_candidates: list[OCRCandidate],
    csv_students: list[Student]
) -> list[StudentMatch]:
    """
    Voting par agrÃ©gation des scores OCR + Fuzzy matching.

    Algorithme:
    1. Pour chaque rÃ©sultat OCR (12 au total)
    2. Parser nom + date
    3. Fuzzy match contre tous les Ã©tudiants CSV
    4. PondÃ©rer par confidence OCR
    5. AgrÃ©ger scores par Ã©tudiant
    6. Retourner top-5

    Returns:
        Top-5 StudentMatch triÃ©s par score dÃ©croissant
    """
    student_scores = defaultdict(lambda: {
        'total_score': 0.0,
        'vote_count': 0,
        'ocr_sources': []
    })

    for ocr_candidate in ocr_candidates:
        # 1. Parser OCR text
        ocr_name, ocr_date = parse_ocr_text(ocr_candidate.text)

        if not ocr_name:
            continue

        # 2. Fuzzy match contre CSV
        for student in csv_students:
            match_score = fuzzy_match_student(ocr_name, ocr_date, student)

            # Seuil bas pour voting (0.3)
            if match_score > 0.3:
                # 3. PondÃ©rer par confidence OCR
                weighted_score = match_score * ocr_candidate.confidence

                # 4. AgrÃ©ger
                student_scores[student.id]['total_score'] += weighted_score
                student_scores[student.id]['vote_count'] += 1
                student_scores[student.id]['ocr_sources'].append({
                    'engine': ocr_candidate.engine,
                    'variant': ocr_candidate.variant,
                    'text': ocr_candidate.text,
                    'score': weighted_score
                })

    # 5. Calculer consensus final
    top_candidates = []

    for student_id, data in sorted(
        student_scores.items(),
        key=lambda x: x[1]['total_score'],
        reverse=True
    )[:5]:  # Top-5 seulement
        # Confidence = score total / nombre d'OCR
        consensus_confidence = data['total_score'] / len(ocr_candidates)

        # Vote agreement = proportion d'OCR qui votent pour cet Ã©tudiant
        vote_agreement = data['vote_count'] / len(ocr_candidates)

        top_candidates.append(StudentMatch(
            student_id=str(student_id),
            confidence=consensus_confidence,
            vote_count=data['vote_count'],
            vote_agreement=vote_agreement,
            sources=data['ocr_sources']
        ))

    return top_candidates
```

### Exemple de RÃ©sultat

```python
# RÃ©sultat du consensus voting
top_candidates = [
    StudentMatch(
        student_id="uuid-student-1",
        confidence=0.85,          # 85% confidence
        vote_count=9,             # 9/12 OCR votent pour cet Ã©tudiant
        vote_agreement=0.75,      # 75% d'accord
        sources=[
            {'engine': 'tesseract', 'variant': 0, 'text': 'JEAN DUPONT 15/05/2008', 'score': 0.82},
            {'engine': 'easyocr', 'variant': 0, 'text': 'Jean Dupont 15-05-2008', 'score': 0.88},
            {'engine': 'paddleocr', 'variant': 1, 'text': 'DUPONT JEAN 15/05/2008', 'score': 0.79},
            # ... 6 autres sources
        ]
    ),
    StudentMatch(
        student_id="uuid-student-2",
        confidence=0.42,          # 42% confidence (candidat secondaire)
        vote_count=3,
        vote_agreement=0.25,
        sources=[...]
    ),
    # ... 3 autres candidats
]
```

---

## ðŸŽ­ Modes d'Identification

### Mode AUTO (Confidence > 0.7)

**CritÃ¨re** : Le top-1 candidat a une confidence > 0.7

**Action** :
- **Assigner automatiquement** l'Ã©tudiant Ã  la copie
- Pas d'intervention humaine requise
- `copy.is_identified = True`
- `copy.status = 'READY'`

```python
if top_candidates[0].confidence > 0.7:
    # AUTO mode
    copy.student_id = top_candidates[0].student_id
    copy.is_identified = True
    copy.status = Copy.Status.READY
    copy.save()

    # Sauvegarder OCR result
    OCRResult.objects.create(
        copy=copy,
        detected_text=top_candidates[0].sources[0]['text'],
        confidence=top_candidates[0].confidence,
        top_candidates=[c.to_dict() for c in top_candidates],
        ocr_mode='AUTO'
    )
```

### Mode SEMI-AUTO (0.4 < Confidence <= 0.7)

**CritÃ¨re** : Le top-1 candidat a une confidence entre 0.4 et 0.7

**Action** :
- **Proposer les top-5 candidats** Ã  l'enseignant
- Interface UI pour sÃ©lectionner le bon Ã©tudiant
- `copy.is_identified = False` (en attente)
- `copy.status = 'PENDING'`

**Interface Frontend** : Voir `IdentificationDesk.vue` (dÃ©jÃ  documentÃ© dans 01.3-Frontend-Vue.md)

```python
if 0.4 < top_candidates[0].confidence <= 0.7:
    # SEMI-AUTO mode
    OCRResult.objects.create(
        copy=copy,
        detected_text=top_candidates[0].sources[0]['text'],
        confidence=top_candidates[0].confidence,
        top_candidates=[c.to_dict() for c in top_candidates],
        ocr_mode='SEMI_AUTO'
    )

    # Copie reste PENDING, en attente de sÃ©lection enseignant
```

**API pour SÃ©lection** :

```python
# POST /api/identification/copies/{copy_id}/select-candidate/
# Body: {"rank": 2}  # Enseignant choisit le 2Ã¨me candidat

copy = Copy.objects.get(id=copy_id)
ocr_result = OCRResult.objects.get(copy=copy)

selected_candidate = ocr_result.top_candidates[rank - 1]

copy.student_id = selected_candidate['student_id']
copy.is_identified = True
copy.status = Copy.Status.READY
copy.save()

# Audit trail
ocr_result.selected_candidate_rank = rank
ocr_result.save()
```

### Mode MANUAL (Confidence <= 0.4)

**CritÃ¨re** : Tous les candidats ont une confidence faible (< 0.4)

**Action** :
- **Recherche manuelle** de l'Ã©tudiant par l'enseignant
- Interface de recherche (nom, email, classe)
- `copy.is_identified = False`
- `copy.status = 'PENDING'`

```python
if not top_candidates or top_candidates[0].confidence <= 0.4:
    # MANUAL mode
    OCRResult.objects.create(
        copy=copy,
        detected_text='',
        confidence=0.0,
        top_candidates=[],
        ocr_mode='MANUAL'
    )

    # Enseignant doit rechercher manuellement
```

**API pour Assignation Manuelle** :

```python
# POST /api/identification/copies/{copy_id}/manual-assign/
# Body: {"student_id": "uuid"}

copy = Copy.objects.get(id=copy_id)

copy.student_id = student_id
copy.is_identified = True
copy.status = Copy.Status.READY
copy.save()

# Audit trail
ocr_result = OCRResult.objects.get(copy=copy)
ocr_result.manual_override = True
ocr_result.save()
```

---

## ðŸ“Š MÃ©triques et Performance

### MÃ©triques Attendues (PRD-19)

| MÃ©trique | Valeur Cible | Mesure |
|----------|--------------|--------|
| **Taux AUTO** | > 70% | % de copies identifiÃ©es automatiquement |
| **Taux SEMI-AUTO** | 15-25% | % nÃ©cessitant sÃ©lection top-5 |
| **Taux MANUAL** | < 10% | % nÃ©cessitant recherche manuelle |
| **Temps OCR** | < 5s/page | Temps de traitement par en-tÃªte |
| **PrÃ©cision AUTO** | > 95% | % d'identifications AUTO correctes |

### Temps de Traitement

**Breakdown pour 1 copie** :

```
1. DÃ©tection header:        0.2s
2. Preprocessing (4 var):   0.5s
3. OCR Tesseract (4 var):   1.0s
4. OCR EasyOCR (4 var):     1.5s
5. OCR PaddleOCR (4 var):   1.2s
6. Fuzzy matching:          0.3s
7. Consensus voting:        0.1s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                      ~4.8s
```

**Optimisations** :
- ExÃ©cuter OCR en parallÃ¨le (multiprocessing)
- Cacher modÃ¨les OCR en mÃ©moire
- Batch processing (traiter plusieurs copies d'un coup)

---

## ðŸ§ª Tests et Validation

### Test Unitaire OCR

```python
# backend/processing/tests/test_ocr_engine.py

import pytest
from processing.services.ocr_engine import MultiLayerOCR
from students.models import Student

def test_ocr_multi_layer_handwritten():
    """Test OCR multi-layer sur Ã©criture manuscrite."""

    # Setup
    ocr_engine = MultiLayerOCR()
    header_image = load_test_image("handwritten_header.jpg")
    students = [
        Student(first_name="Jean", last_name="Dupont", date_of_birth="2008-05-15"),
        Student(first_name="Marie", last_name="Martin", date_of_birth="2007-12-03")
    ]

    # Execute
    result = ocr_engine.extract_text_with_candidates(header_image, students)

    # Assert
    assert result.top_candidates
    assert len(result.top_candidates) <= 5
    assert result.top_candidates[0].student_id == students[0].id
    assert result.top_candidates[0].confidence > 0.7
    assert result.ocr_mode == 'AUTO'


def test_consensus_voting_multiple_engines():
    """VÃ©rifier que le voting agrÃ¨ge correctement."""

    # 3 OCR engines votent pour "Jean Dupont"
    # 1 OCR engine vote pour "Marie Martin" (erreur)
    # â†’ Consensus devrait Ãªtre "Jean Dupont"

    ocr_candidates = [
        OCRCandidate('tesseract', 0, 'JEAN DUPONT 15/05/2008', 0.8),
        OCRCandidate('easyocr', 0, 'Jean Dupont 15-05-2008', 0.9),
        OCRCandidate('paddleocr', 1, 'DUPONT JEAN 15/05/2008', 0.75),
        OCRCandidate('tesseract', 1, 'MARIE MARTIN 03/12/2007', 0.6),  # Outlier
    ]

    students = [...]

    top_candidates = consensus_vote(ocr_candidates, students)

    assert top_candidates[0].student_id == "jean-dupont-id"
    assert top_candidates[0].vote_count >= 3  # Au moins 3 moteurs d'accord
```

### Test d'IntÃ©gration Batch

```python
def test_batch_processing_with_ocr():
    """Test traitement batch complet avec OCR multi-layer."""

    # Setup
    pdf_path = "test_data/eval_loi_binom_log.pdf"  # 88 pages A3, 28 Ã©tudiants
    csv_path = "test_data/G3_EDS_MATHS.csv"

    # Execute
    processor = BatchA3Processor()
    result = processor.process(pdf_path, csv_path)

    # Assert
    assert result.copies_created == 28
    assert result.auto_identified >= 20  # >70%
    assert result.semi_auto <= 7         # <25%
    assert result.manual <= 3            # <10%
```

---

## ðŸ“ Conclusion

Le workflow OCR PRD-19 offre une identification robuste des copies grÃ¢ce Ã  l'approche multi-layer avec consensus voting.

**AmÃ©liorations vs PRD-18** :
- **Taux de succÃ¨s** : 30% â†’ >70% (AUTO) + 20% (SEMI-AUTO)
- **3 moteurs OCR** au lieu d'1 seul
- **Mode SEMI-AUTO** : assistance intelligente (top-5) au lieu de recherche manuelle complÃ¨te
- **Preprocessing avancÃ©** : 4 variantes optimisÃ©es
- **Audit trail** : traÃ§abilitÃ© complÃ¨te des dÃ©cisions OCR

---

**Document rÃ©digÃ© par :**
**Alaeddine BEN RHOUMA**
*Lead Senior Documentation & Architecture*
Date : 3 FÃ©vrier 2026
